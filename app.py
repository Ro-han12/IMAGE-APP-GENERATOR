
import streamlit as st
from dotenv import load_dotenv
import os
from diffusers import StableDiffusionPipeline
import torch

# Load environment variables
load_dotenv()

# Load Huggingface Diffusion model with MPS backend
@st.cache(allow_output_mutation=True)
def load_diffusion_model():
    pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
    pipe = pipe.to("mps")
    
    # First-time "warmup" pass
    prompt = "warmup prompt"
    _ = pipe(prompt, num_inference_steps=1)
    
    return pipe

# Function to generate images using Huggingface Diffusion
def generate_images_using_huggingface_diffusion(model, text):
    prompt = text
    image = model(prompt).images[0]
    return image

# Streamlit App
def main():
    st.sidebar.title("Select your choice")
    choice = st.sidebar.radio("", ["Home", "Huggingface Diffusion"])

    if choice == "Home":
        st.title("AI Image Generation App")
        with st.expander("About the App"):
            st.write("This is a simple image generation app that uses AI to generate images from text prompts.")

    elif choice == "Huggingface Diffusion":
        st.subheader("Image generation using Huggingface Diffusion")
        input_prompt = st.text_input("Enter your text prompt")
        if input_prompt:
            model = load_diffusion_model()  # Load the model
            if st.button("Generate Image"):
                st.info("Generating image...")
                image_output = generate_images_using_huggingface_diffusion(model, input_prompt)
                st.success("Image Generated Successfully")
                st.image(image_output, caption="Generated by Huggingface Diffusion", use_column_width=True)

if __name__ == "__main__":
    main()
